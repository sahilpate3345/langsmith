Built a LangGraph-based workflow to model multi-step LLM execution using graph nodes

ğŸ“š Implemented Retrieval-Augmented Generation (RAG) to ground responses with external documents

ğŸ” Integrated LangSmith observability to trace prompts, retrievals, and LLM outputs

ğŸ§  Debugged hallucinations by inspecting retrieved context vs generated answers

ğŸ“Š Visualized graph execution flow, latency, and token usage in LangSmith

âš™ï¸ Designed modular nodes for query processing, retrieval, and generation

ğŸš€ Applied production-style GenAI architecture instead of simple prompt chaining
