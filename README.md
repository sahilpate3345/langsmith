Built a LangGraph-based RAG pipeline with stateful execution and multi-step LLM workflows.

Integrated LangSmith to enable end-to-end observability, tracing each node in the LangGraph execution.

Implemented Retrieval-Augmented Generation (RAG) using document retrieval and context-aware LLM responses.

Visualized graph-level execution flow, token usage, latency, and prompt-response cycles in LangSmith.

Debugged LLM hallucinations by inspecting retriever outputs and prompt context via LangSmith traces.

Designed modular graph nodes for query processing, retrieval, context injection, and generation.

Applied production-ready practices by separating workflow logic (LangGraph) from observability (LangSmith).

Improved answer accuracy by grounding LLM responses with retrieved documents instead of model memory.

Used environment-based configuration to manage LangSmith projects and tracing securely.

Gained hands-on experience with modern agent-free GenAI architectures used in real-world systems.
